{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree\n",
    "import numpy as np\n",
    "import mrcnn.utils\n",
    "import mrcnn.config\n",
    "import mrcnn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['BG', 'table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableBankDataset(mrcnn.utils.Dataset):\n",
    "\n",
    "    def load_dataset(self, dataset_dir, is_train=True):\n",
    "        # Adds information (image ID, image path, and annotation file path) about each image in a dictionary.\n",
    "        self.add_class(\"dataset\", 1, \"table\")\n",
    "        \n",
    "        images_dir = dataset_dir + '/images/'\n",
    "        annotations_dir = dataset_dir + '/annotations/'\n",
    "\n",
    "        annotations = json.load(open(dataset_dir + '/annotations/' + 'tablebank_latex_train.json'))\n",
    "\n",
    "        for i, image in enumerate(annotations[\"images\"]):\n",
    "            if i > 50000:\n",
    "                break\n",
    "            for annotation in annotations[\"annotations\"]:\n",
    "                if image[\"id\"] == annotation[\"id\"] and os.path.exists(images_dir + image[\"file_name\"]):\n",
    "                    img_path = images_dir + image[\"file_name\"]\n",
    "                    img_info = annotation\n",
    "                    img_info[\"width\"] = image[\"width\"]\n",
    "                    img_info[\"height\"] = image[\"height\"]\n",
    "                    self.add_image('dataset', image_id=image[\"id\"], path=img_path, annotation=img_info)\n",
    "                    break\n",
    "    \n",
    "    # A helper method to extract the bounding boxes from the annotation file\n",
    "    def extract_boxes(self, filename):\n",
    "        img_info = filename\n",
    "        boxes = []\n",
    "        boxes.append(img_info[\"bbox\"])\n",
    "        width = img_info[\"width\"]\n",
    "        height = img_info[\"height\"]\n",
    "        return boxes, width, height\n",
    "\n",
    "    # Loads the binary masks for an image.\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        path = info['annotation']\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        masks = np.zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        \n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            class_ids.append(self.class_names.index('table'))\n",
    "        return masks, np.asarray(class_ids, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableBankConfig(mrcnn.config.Config):\n",
    "    NAME = \"mask_rcnn_tablebank_cfg\"\n",
    "\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    BACKBONE = \"resnet50\"\n",
    "    NUM_CLASSES = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "train_dataset = TableBankDataset()\n",
    "train_dataset.load_dataset(dataset_dir='C:/Users/dsash/Repository/table/TableBank/Detection', is_train=True)\n",
    "train_dataset.prepare()\n",
    "\n",
    "# Validation\n",
    "validation_dataset = TableBankDataset()\n",
    "validation_dataset.load_dataset(dataset_dir='C:/Users/dsash/Repository/table/TableBank/Detection', is_train=False)\n",
    "validation_dataset.prepare()\n",
    "\n",
    "# Model Configuration\n",
    "tablebank_config = TableBankConfig()\n",
    "\n",
    "# Build the Mask R-CNN Model Architecture\n",
    "model = mrcnn.model.MaskRCNN(mode='training', \n",
    "                             model_dir=os.getcwd(), \n",
    "                             config=tablebank_config)\n",
    "\n",
    "model.load_weights(filepath='mask_rcnn_coco.h5', \n",
    "                   by_name=True, \n",
    "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "model.train(train_dataset=train_dataset, \n",
    "            val_dataset=validation_dataset, \n",
    "            learning_rate=tablebank_config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')\n",
    "\n",
    "model_path = 'tablebank_mask_rcnn_trained.h5'\n",
    "model.keras_model.save_weights(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
